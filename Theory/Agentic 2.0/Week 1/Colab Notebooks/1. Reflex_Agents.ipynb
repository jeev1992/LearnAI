{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reflex Agents\n",
        "\n",
        "Reflex AI Agents are the most fundamental class of intelligent agents. They are designed to react immediately to their environment without \"thinking\" about the future or analyzing complex consequences.\n",
        "\n",
        "They function like a human reflex (e.g., blinking when an object flies toward your eye)—purely reactive and fast.\n",
        "\n",
        "Reflex agents operate on a simple loop known as Condition-Action Rules (often called \"If-Then\" logic).\n",
        "\n",
        "- **Condition**: The agent perceives a specific state in the environment.\n",
        "\n",
        "- **Action**: The agent immediately executes a pre-assigned task associated with that state.\n",
        "\n",
        "Key Characteristic: They do not plan, strategize, or simulate future outcomes. They only care about the \"here and now.\""
      ],
      "metadata": {
        "id": "s6nyseA9wGc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we’ll explore two types of reflex agents through the classic Vacuum World scenario (two rooms: A and B):\n",
        "\n",
        "1. **Simple Reflex Agent:** Reacts only to\n",
        "the current room’s cleanliness.\n",
        "2. **Model-Based Reflex Agent:** Maintains an internal model of the world to avoid redundant actions."
      ],
      "metadata": {
        "id": "Y_DbSK49B7en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Simple Reflex Agent**\n",
        "\n",
        "The Simple Reflex Agent follows a minimal set of rules:\n",
        "\n",
        "- If the current room is dirty → clean it.\n",
        "- If the current room is clean → move to the other room.\n",
        "\n",
        "**Limitation**:\n",
        "This agent has **no memory**. If both rooms are clean, it will endlessly oscillate between them because it cannot recall whether the other room has already been cleaned."
      ],
      "metadata": {
        "id": "OWhEm83HwTPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSSI3C77vxq9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class SimpleReflexAgent:\n",
        "    def __init__(self):\n",
        "        # No internal memory (state) here!\n",
        "        pass\n",
        "\n",
        "    def decide(self, percept):\n",
        "        \"\"\"\n",
        "        Receives percept: (current_location, is_dirty)\n",
        "        Returns action: 'Suction on', 'Right', 'Left'\n",
        "        \"\"\"\n",
        "        location, is_dirty = percept\n",
        "\n",
        "        # Rule 1: If current spot is dirty, clean it.\n",
        "        if is_dirty:\n",
        "            return \"Suction on\"\n",
        "\n",
        "        # Rule 2: If clean, move to the other room.\n",
        "        elif location == 'A':\n",
        "            return \"Right\"\n",
        "        elif location == 'B':\n",
        "            return \"Left\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simulation: Simple Reflex Agent in Action\n",
        "We initialize the environment with both rooms clean and run a short simulation to observe the agent’s behavior."
      ],
      "metadata": {
        "id": "AD6A79WZwvi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment State: Both rooms are initially clean\n",
        "env_state = {'A': True, 'B': False} # False = Clean\n",
        "agent_location = 'A'\n",
        "agent = SimpleReflexAgent()\n",
        "\n",
        "print(\"--- Simple Reflex Simulation ---\")\n",
        "for i in range(4):\n",
        "    # 1. Get Percept\n",
        "    is_dirty = env_state[agent_location]\n",
        "    percept = (agent_location, is_dirty)\n",
        "\n",
        "    # 2. Decide\n",
        "    action = agent.decide(percept)\n",
        "\n",
        "    print(f\"Loc: {agent_location} | Dirty: {is_dirty} -> Action: {action}\")\n",
        "\n",
        "    # 3. Update Environment\n",
        "    if action == \"Suction on\":\n",
        "        env_state[agent_location] = False\n",
        "    elif action == \"Right\":\n",
        "        agent_location = 'B'\n",
        "    elif action == \"Left\":\n",
        "        agent_location = 'A'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcWphjSwnjQ",
        "outputId": "2d5a4854-6c53-4c9d-9c41-390edd2d6cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Simple Reflex Simulation ---\n",
            "Loc: A | Dirty: True -> Action: Suction on\n",
            "Loc: A | Dirty: False -> Action: Right\n",
            "Loc: B | Dirty: False -> Action: Left\n",
            "Loc: A | Dirty: False -> Action: Right\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Notice how it keeps moving 'Right' and 'Left' even if everything is clean?\n",
        "<br>It lacks the memory to know it's \"Done\"."
      ],
      "metadata": {
        "id": "Oe7NMgwEx39k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Model-Based Reflex Agent**\n",
        "To overcome the limitations of the simple reflex agent, we introduce a **Model-Based Reflex Agent**. This agent maintains an internal state—a dictionary representing what it knows about the world.\n",
        "\n",
        "**Advantages**\n",
        "- **Internal Memory:** Tracks the cleanliness status of both rooms.\n",
        "- **Smarter Decisions:** If its internal model indicates both rooms are clean, it stops acting (i.e., returns `\"NoOp (Job Done)\"`).\n",
        "- **Avoids Redundancy:** No endless back-and-forth when the task is complete."
      ],
      "metadata": {
        "id": "6dJ0J_jux-OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBasedReflexAgent:\n",
        "    def __init__(self):\n",
        "        # Internal State: Keeps track of the world status\n",
        "        self.model = {\n",
        "            'A': 'Unknown',\n",
        "            'B': 'Unknown'\n",
        "        }\n",
        "\n",
        "    def update_state(self, location, is_dirty):\n",
        "        \"\"\"Updates internal model based on current percept\"\"\"\n",
        "        self.model[location] = 'Dirty' if is_dirty else 'Clean'\n",
        "\n",
        "    def decide(self, percept):\n",
        "        location, is_dirty = percept\n",
        "\n",
        "        # 1. Update Internal State first\n",
        "        self.update_state(location, is_dirty)\n",
        "\n",
        "        # 2. Check \"World Model\" to make a decision\n",
        "\n",
        "        # Rule: If internal model says EVERYWHERE is clean, Stop.\n",
        "        # (A simple reflex agent cannot do this)\n",
        "        if all(status == 'Clean' for status in self.model.values()):\n",
        "            return \"NoOp (Job Done)\"\n",
        "\n",
        "        # Standard Cleaning Rules\n",
        "        if is_dirty:\n",
        "            return \"Suction on\"\n",
        "        elif location == 'A':\n",
        "            return \"Right\"\n",
        "        elif location == 'B':\n",
        "            return \"Left\""
      ],
      "metadata": {
        "id": "TwrDtzqiyMl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simulation: Model-Based Reflex Agent in Action\n",
        "Now we simulate the model-based agent in a scenario where Room B starts dirty. Notice how it cleans efficiently and then stops once both rooms are confirmed clean."
      ],
      "metadata": {
        "id": "i6QDicRjyXY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_state = {'A': False, 'B': True} # A is Clean, B is Dirty\n",
        "agent_location = 'A'\n",
        "agent = ModelBasedReflexAgent()\n",
        "\n",
        "print(\"\\n--- Model-Based Simulation ---\")\n",
        "for i in range(5):\n",
        "    is_dirty = env_state[agent_location]\n",
        "    percept = (agent_location, is_dirty)\n",
        "\n",
        "    action = agent.decide(percept)\n",
        "\n",
        "    print(f\"Loc: {agent_location} | Dirty: {is_dirty} | Model: {agent.model} -> Action: {action}\")\n",
        "\n",
        "    if action == \"NoOp (Job Done)\":\n",
        "        break # The agent is smart enough to stop!\n",
        "\n",
        "    if action == \"Suction on\":\n",
        "        env_state[agent_location] = False\n",
        "    elif action == \"Right\":\n",
        "        agent_location = 'B'\n",
        "    elif action == \"Left\":\n",
        "        agent_location = 'A'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5yStNcXybH5",
        "outputId": "bd1b6b7f-9cc9-409c-9d60-6a59889c7396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model-Based Simulation ---\n",
            "Loc: A | Dirty: False | Model: {'A': 'Clean', 'B': 'Unknown'} -> Action: Right\n",
            "Loc: B | Dirty: True | Model: {'A': 'Clean', 'B': 'Dirty'} -> Action: Suction on\n",
            "Loc: B | Dirty: False | Model: {'A': 'Clean', 'B': 'Clean'} -> Action: NoOp (Job Done)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Key Insight: The model-based agent uses its internal world model to recognize when the job is truly done, avoiding the infinite loop that traps the simple reflex agent."
      ],
      "metadata": {
        "id": "_GU3Hsk-CKzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "These examples highlight a foundational principle in intelligent agent design:  \n",
        "**Even without explicit planning, maintaining an internal model of the world enables significantly smarter and more efficient behavior.**\n",
        "\n",
        "- The **Simple Reflex Agent** reacts purely to the current percept, which can lead to redundant or infinite actions (e.g., oscillating between clean rooms).\n",
        "- In contrast, the **Model-Based Reflex Agent** uses memory to track what it knows about the environment. This allows it to recognize when a task is truly complete and avoid unnecessary actions.\n",
        "\n",
        "This idea—augmenting reactivity with state—scales directly into more sophisticated agent architectures you’ll explore later in the course, such as **goal-based agents** (which plan to achieve specific objectives) and **utility-based agents** (which optimize for preference or efficiency).\n",
        "\n",
        "By evolving from reflexive to stateful reasoning, agents become not just responsive, but *purposeful*."
      ],
      "metadata": {
        "id": "KywvE8-_CMPa"
      }
    }
  ]
}